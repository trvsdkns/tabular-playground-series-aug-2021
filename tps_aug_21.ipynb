{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unsigned-tyler",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-crisis",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "print('train shape:',train.shape)\n",
    "print('test shape:',test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validation data\n",
    "X_train, X_valid = np.split(train.sample(frac=1, random_state=42), \n",
    "                       [int(.8*len(train))])\n",
    "\n",
    "y_train = X_train['loss'].values\n",
    "y_valid = X_valid['loss'].values\n",
    "\n",
    "X_train = X_train.drop(columns = ['loss','id'])\n",
    "X_valid = X_valid.drop(columns = ['loss','id'])\n",
    "\n",
    "\n",
    "# Test data\n",
    "X_test = test.drop(columns = ['id'])\n",
    "\n",
    "print('Train set:', X_train.shape)\n",
    "print('Validation set:', X_valid.shape)\n",
    "print('Test set:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess data\n",
    "\n",
    "features_num = list(X_train.columns[0:99])\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), features_num)\n",
    ")\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_valid = preprocessor.transform(X_valid)\n",
    "X_test = preprocessor.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-advertising",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-acquisition",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [X_train.shape[1]]\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.BatchNormalization(input_shape=input_shape),\n",
    "    layers.Dense(150, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(25, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=SGD(lr=0.01),\n",
    "    loss='mse',\n",
    "    metrics=[keras.metrics.RootMeanSquaredError()],\n",
    ")\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "    patience=20, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-context",
   "metadata": {},
   "source": [
    "# Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-seeker",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE\n",
    "predicted_train = model.predict(X_train)\n",
    "predicted_valid = model.predict(X_valid)\n",
    "rmse_train = metrics.mean_squared_error(y_train, predicted_train, squared=False)\n",
    "rmse_valid = metrics.mean_squared_error(y_valid, predicted_valid, squared=False)\n",
    "print('Training RMSE: ', rmse_train)\n",
    "print('Validation RMSE: ', rmse_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-walter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss curves\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "# Set Matplotlib defaults\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('animation', html='html5')\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[0:, ['root_mean_squared_error', 'val_root_mean_squared_error']].plot()\n",
    "print((\"Minimum Root Mean Squared Error: {:0.4f}\").format(history_df['root_mean_squared_error'].min()))\n",
    "print((\"Minimum Validation Root Mean Squared Error: {:0.4f}\").format(history_df['val_root_mean_squared_error'].min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-award",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-brother",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-breakfast",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-soviet",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.read_csv(\"sample_submission.csv\")\n",
    "preds.loss = y_pred\n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-treasurer",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.to_csv('submission14.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
